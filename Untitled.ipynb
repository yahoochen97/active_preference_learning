{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "from scipy.stats import norm\n",
    "from matplotlib import pyplot as plt\n",
    "from gpytorch.models import ApproximateGP\n",
    "from gpytorch.variational import CholeskyVariationalDistribution\n",
    "from gpytorch.variational import UnwhitenedVariationalStrategy\n",
    "from gpytorch.likelihoods import BernoulliLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_pair(s1, s2, coder_quality=1):\n",
    "    '''\n",
    "    Label a pair with coder quality.\n",
    "\n",
    "    Math: \n",
    "        p = ncdf(coder*(s1-s2))\n",
    "        label = 2*Bernouli(p) - 1\n",
    "    '''\n",
    "    p = norm.cdf(coder_quality*(s1-s2))\n",
    "    label = np.random.binomial(n=1, p=p)\n",
    "    return 2*label-1\n",
    "\n",
    "train_x = torch.rand(size=(10,2))*2-1\n",
    "train_y = torch.tensor([label_pair(train_x[i,0].data,train_x[i,1].data) for i in range(train_x.shape[0])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPClassificationModel(ApproximateGP):\n",
    "    def __init__(self, train_x):\n",
    "        variational_distribution = CholeskyVariationalDistribution(train_x.size(0))\n",
    "        variational_strategy = UnwhitenedVariationalStrategy(\n",
    "            self, train_x, variational_distribution, learn_inducing_locations=False\n",
    "        )\n",
    "        super(GPClassificationModel, self).__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        latent_pred = gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "        return latent_pred\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = BernoulliLikelihood()\n",
    "model = GPClassificationModel(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/100 - Loss: 0.909\n",
      "Iter 2/100 - Loss: 4.891\n",
      "Iter 3/100 - Loss: 8.589\n",
      "Iter 4/100 - Loss: 3.837\n",
      "Iter 5/100 - Loss: 6.389\n",
      "Iter 6/100 - Loss: 6.716\n",
      "Iter 7/100 - Loss: 6.203\n",
      "Iter 8/100 - Loss: 5.051\n",
      "Iter 9/100 - Loss: 4.171\n",
      "Iter 10/100 - Loss: 3.638\n",
      "Iter 11/100 - Loss: 3.245\n",
      "Iter 12/100 - Loss: 2.852\n",
      "Iter 13/100 - Loss: 2.416\n",
      "Iter 14/100 - Loss: 2.188\n",
      "Iter 15/100 - Loss: 1.938\n",
      "Iter 16/100 - Loss: 1.709\n",
      "Iter 17/100 - Loss: 1.614\n",
      "Iter 18/100 - Loss: 1.595\n",
      "Iter 19/100 - Loss: 1.573\n",
      "Iter 20/100 - Loss: 1.556\n",
      "Iter 21/100 - Loss: 1.555\n",
      "Iter 22/100 - Loss: 1.557\n",
      "Iter 23/100 - Loss: 1.555\n",
      "Iter 24/100 - Loss: 1.546\n",
      "Iter 25/100 - Loss: 1.529\n",
      "Iter 26/100 - Loss: 1.506\n",
      "Iter 27/100 - Loss: 1.479\n",
      "Iter 28/100 - Loss: 1.448\n",
      "Iter 29/100 - Loss: 1.415\n",
      "Iter 30/100 - Loss: 1.381\n",
      "Iter 31/100 - Loss: 1.348\n",
      "Iter 32/100 - Loss: 1.316\n",
      "Iter 33/100 - Loss: 1.286\n",
      "Iter 34/100 - Loss: 1.260\n",
      "Iter 35/100 - Loss: 1.237\n",
      "Iter 36/100 - Loss: 1.217\n",
      "Iter 37/100 - Loss: 1.199\n",
      "Iter 38/100 - Loss: 1.182\n",
      "Iter 39/100 - Loss: 1.164\n",
      "Iter 40/100 - Loss: 1.143\n",
      "Iter 41/100 - Loss: 1.122\n",
      "Iter 42/100 - Loss: 1.099\n",
      "Iter 43/100 - Loss: 1.076\n",
      "Iter 44/100 - Loss: 1.055\n",
      "Iter 45/100 - Loss: 1.036\n",
      "Iter 46/100 - Loss: 1.018\n",
      "Iter 47/100 - Loss: 1.002\n",
      "Iter 48/100 - Loss: 0.986\n",
      "Iter 49/100 - Loss: 0.972\n",
      "Iter 50/100 - Loss: 0.957\n",
      "Iter 51/100 - Loss: 0.944\n",
      "Iter 52/100 - Loss: 0.930\n",
      "Iter 53/100 - Loss: 0.917\n",
      "Iter 54/100 - Loss: 0.904\n",
      "Iter 55/100 - Loss: 0.892\n",
      "Iter 56/100 - Loss: 0.880\n",
      "Iter 57/100 - Loss: 0.869\n",
      "Iter 58/100 - Loss: 0.859\n",
      "Iter 59/100 - Loss: 0.850\n",
      "Iter 60/100 - Loss: 0.841\n",
      "Iter 61/100 - Loss: 0.833\n",
      "Iter 62/100 - Loss: 0.825\n",
      "Iter 63/100 - Loss: 0.818\n",
      "Iter 64/100 - Loss: 0.811\n",
      "Iter 65/100 - Loss: 0.804\n",
      "Iter 66/100 - Loss: 0.798\n",
      "Iter 67/100 - Loss: 0.792\n",
      "Iter 68/100 - Loss: 0.786\n",
      "Iter 69/100 - Loss: 0.781\n",
      "Iter 70/100 - Loss: 0.776\n",
      "Iter 71/100 - Loss: 0.772\n",
      "Iter 72/100 - Loss: 0.768\n",
      "Iter 73/100 - Loss: 0.764\n",
      "Iter 74/100 - Loss: 0.760\n",
      "Iter 75/100 - Loss: 0.757\n",
      "Iter 76/100 - Loss: 0.753\n",
      "Iter 77/100 - Loss: 0.750\n",
      "Iter 78/100 - Loss: 0.747\n",
      "Iter 79/100 - Loss: 0.744\n",
      "Iter 80/100 - Loss: 0.741\n",
      "Iter 81/100 - Loss: 0.738\n",
      "Iter 82/100 - Loss: 0.736\n",
      "Iter 83/100 - Loss: 0.734\n",
      "Iter 84/100 - Loss: 0.731\n",
      "Iter 85/100 - Loss: 0.729\n",
      "Iter 86/100 - Loss: 0.727\n",
      "Iter 87/100 - Loss: 0.726\n",
      "Iter 88/100 - Loss: 0.724\n",
      "Iter 89/100 - Loss: 0.722\n",
      "Iter 90/100 - Loss: 0.721\n",
      "Iter 91/100 - Loss: 0.719\n",
      "Iter 92/100 - Loss: 0.718\n",
      "Iter 93/100 - Loss: 0.717\n",
      "Iter 94/100 - Loss: 0.715\n",
      "Iter 95/100 - Loss: 0.714\n",
      "Iter 96/100 - Loss: 0.713\n",
      "Iter 97/100 - Loss: 0.712\n",
      "Iter 98/100 - Loss: 0.711\n",
      "Iter 99/100 - Loss: 0.710\n",
      "Iter 100/100 - Loss: 0.709\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "# num_data refers to the number of training datapoints\n",
    "mll = gpytorch.mlls.VariationalELBO(likelihood, model, train_y.numel())\n",
    "training_iterations = 100\n",
    "for i in range(training_iterations):\n",
    "    # Zero backpropped gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Get predictive output\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f' % (i + 1, training_iterations, loss.item()))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Go into eval mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test x are regularly spaced by 0.01 0,1 inclusive\n",
    "    test_x = torch.linspace(0, 1, 101)\n",
    "    # Get classification predictions\n",
    "    observed_pred = likelihood(model(test_x))\n",
    "\n",
    "    # Initialize fig and axes for plot\n",
    "    f, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    # Get the predicted labels (probabilites of belonging to the positive class)\n",
    "    # Transform these probabilities to be 0/1 labels\n",
    "    pred_labels = observed_pred.mean.ge(0.5).float()\n",
    "    ax.plot(test_x.numpy(), pred_labels.numpy(), 'b')\n",
    "    ax.set_ylim([-1, 2])\n",
    "    ax.legend(['Observed Data', 'Mean'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68cfed0f241222fe61652af3dd310f12dd5267fc077ebbf849de2b6fa665024d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
